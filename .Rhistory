temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig, p = .24
#JOL vs READ
temp = t.test(mixed.encoding$JOL, mixed.encoding$READ, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #non-sig, p = .32
##Interaction was sig, let's break it down
tapply(mixed$Scored, list(mixed$Encoding, mixed$Direction), mean)
setwd("~/GitHub/Dissertation-EX2-4/1 Output/EX 3")
###Set up####
source("Ex 3 Data Cleaning.R")
##Read in the Pure U data
F3 = read.csv("Pure Unrelated/FREQ_PURE_U.csv")
J3 = read.csv("Pure Unrelated/JOL_PURE_U.csv")
R3 = read.csv("Pure Unrelated/Study_Pure_U.csv")
####Get n's####
##1 = Mixed
##2 = Pure B
##3 = Pure U
#Frequency
length(unique(F1$id)) #43 #Mixed
length(unique(F2$id)) #42 #Pure B
length(unique(F3$id)) #31 #Pure U
#JOL
length(unique(J1$id)) #40 #Mixed
length(unique(J2$id)) #41 #Pure B
length(unique(J3$id)) #30 #Pure U
#Study
length(unique(R1$id)) #37 #Mixed
length(unique(R2$id)) #37 #Pure B
length(unique(R3$id)) #33 #Pure U
#Fix colnames
colnames(F3)[3] = "Freq"
####Arrange data for Models####
##Combine on Encoding strategy
FREQ2 = rbind(F1, F2, F3)
JOL2 = rbind(J1, J2, J3)
Study2 = rbind(R1, R2, R3)
####Make ANOVA DATASETS####
Final = rbind(FREQ2[ , -3], JOL2[ , -3], Study2)
mixed = subset(Final,
Final$List_Type == "Mixed")
Pure_U = subset(Final,
Final$List_Type == "Pure U")
Pure_B = subset(Final,
Final$List_Type == "Pure B")
Pure_U$List_Type2 = rep("Pure U")
Pure_B$List_Type2 = rep("Pure B")
##Make pure data
pure = rbind(Pure_B, Pure_U)
##Get means
tapply(mixed$Scored, list(mixed$Encoding, mixed$Direction), mean)
tapply(pure$Scored, list(pure$Encoding, pure$Direction), mean)
####ANOVAS####
##Mixed lists
model5 = ezANOVA(mixed,
wid = id,
between = Encoding,
within = Direction,
dv = Scored,
return_aov = T,
type = 3,
detailed = T)
model5
model5$ANOVA$MSE = model5$ANOVA$SSd/model5$ANOVA$DFd
model5$ANOVA$MSE
aovEffectSize(model5, effectSize = "pes")
length(unique(mixed$id))
##Pure lists
model6 = ezANOVA(pure,
wid = id,
between = .(Encoding, Direction),
dv = Scored,
return_aov = T,
type = 3,
detailed = T)
model6 #.07
model6 #.11
length(unique(pure$id))
model6$ANOVA$MSE = model6$ANOVA$SSd/model6$ANOVA$DFd
model6$ANOVA$MSE
aovEffectSize(model6, effectSize = "pes")
####Post-hocs####
##Let's do the mixed lists first
mixed = mixed[ , c(1, 2, 4, 5, 3)]
#main effect of direction
tapply(mixed$Scored, mixed$Direction, mean) #This will be sig based on ANOVA
#Don't need to run t-test here because only two comparisons
#main effect of encoding #Did not come out sig but breaking down anyways
tapply(mixed$Scored, mixed$Encoding, mean)
mixed.encoding = cast(mixed, id ~ Encoding, mean)
##JOL vs FREQ
temp = t.test(mixed.encoding$Frequency, mixed.encoding$JOL, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig
##FREQ VS READ
temp = t.test(mixed.encoding$Frequency, mixed.encoding$READ, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig, p = .27
#JOL vs READ
temp = t.test(mixed.encoding$JOL, mixed.encoding$READ, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #non-sig, p = .15
#Nothing differs
##Interaction was sig, let's break it down
tapply(mixed$Scored, list(mixed$Encoding, mixed$Direction), mean)
#setup
mixed.jol = subset(mixed, mixed$Encoding == "JOL")
mixed.freq = subset(mixed, mixed$Encoding == "Frequency")
mixed.read = subset(mixed, mixed$Encoding == "READ")
mixed.jol2 = cast(mixed.jol, id ~ Direction, mean)
mixed.freq2 = cast(mixed.freq, id ~ Direction, mean)
mixed.read2 = cast(mixed.read, id ~ Direction, mean)
#jol descriptives
apply(mixed.jol2, 2, mean, na.rm = T)
x = apply(mixed.jol2, 2, sd, na.rm = T)
x / sqrt(length(unique(mixed.jol2$id))) * 1.96
#freq descriptives
apply(mixed.freq2, 2, mean, na.rm = T)
x = apply(mixed.freq2, 2, sd, na.rm = T)
x / sqrt(length(unique(mixed.freq2$id))) * 1.96
#read descriptives
apply(mixed.read2, 2, mean, na.rm = T)
x = apply(mixed.read2, 2, sd, na.rm = T)
x / sqrt(length(unique(mixed.read2$id))) * 1.96
#run the t-tests
#BACKWARD pairs
#JOL vs FREQ
temp = t.test(mixed.jol2$B, mixed.freq2$B, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig, p =.39
##JOL vs READ
temp = t.test(mixed.jol2$B, mixed.read2$B, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #significant! 0 = .002
##FREQ vs READ
temp = t.test(mixed.freq2$B, mixed.read2$B, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #SIGNIFICANT! p = .03
##For forward pairs, recall is significantly higher when making JOLs/FREQs relative to read
#Recall does not differ between JOLs and FREQs
#unrelated PAIRS
#JOL VS FREQ
temp = t.test(mixed.jol2$U, mixed.freq2$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig
#JOL VS READ
temp = t.test(mixed.jol2$U, mixed.read2$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #non-sig
##FREQ VS READ
temp = t.test(mixed.freq2$U, mixed.read2$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig
##For mixed lists, Recall of unrelated pairs doesn't differ as a function of encoding group
####Now for the pure lists####
pure = pure[ , c(1, 2, 4, 5, 3)]
#main effect of direction
tapply(pure$Scored, pure$Direction, mean) #This will be sig based on ANOVA
#main effect of encoding
tapply(pure$Scored, pure$Encoding, mean)
pure.encoding = cast(pure, id ~ Encoding, mean)
##FREQ VS JOL
temp = t.test(pure.encoding$Frequency, pure.encoding$JOL, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-Sig
##FREQ VS READ
temp = t.test(pure.encoding$Frequency, pure.encoding$READ, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
##JOL VS READ
temp = t.test(pure.encoding$JOL, pure.encoding$READ, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #.16
##interaction
tapply(pure$Scored, list(pure$Encoding, pure$Direction), mean)
#setup
pure.jol = subset(pure, pure$Encoding == "JOL")
pure.freq = subset(pure, pure$Encoding == "Frequency")
pure.read = subset(pure, pure$Encoding == "READ")
pure.jol2 = cast(pure.jol, id ~ Direction, mean)
pure.freq2 = cast(pure.freq, id ~ Direction, mean)
pure.read2 = cast(pure.read, id ~ Direction, mean)
#jol descriptives
apply(pure.jol2, 2, mean, na.rm = T)
x = apply(pure.jol2, 2, sd, na.rm = T)
x / sqrt(length(unique(pure.jol2$id))) * 1.96
#freq descriptives
apply(pure.freq2, 2, mean, na.rm = T)
x = apply(pure.freq2, 2, sd, na.rm = T)
x / sqrt(length(unique(pure.freq2$id))) * 1.96
#read descriptives
apply(pure.read2, 2, mean, na.rm = T)
x = apply(pure.read2, 2, sd, na.rm = T)
x / sqrt(length(unique(pure.read2$id))) * 1.96
#run the t-tests
#Forward pairs
#jol vs freq
temp = t.test(pure.jol2$B, pure.freq2$B, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig
#jol vs read
temp = t.test(pure.jol2$B, pure.read2$B, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
#freq vs read
temp = t.test(pure.freq2$B, pure.read2$B, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
#unrelated
#JOL vs FREQ
temp = t.test(pure.jol2$U, pure.freq2$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig
#JOL vs READ
temp = t.test(pure.jol2$U, pure.read2$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #non-sig
#freq vs read
temp = t.test(pure.freq2$U, pure.read2$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Non-sig
setwd("F:/02 Missouri State/Dr. Brattin Project/Part 1")
##setup
##set path to where txt files are located
pathname = "E:/Dr. Brattin Project/Part 1/completed txt docs" ##sub out the e depending on computer being used.
library(lsa)
library(tm)
install.packages("lsa")
install.packages("tm")
##setup
##set path to where txt files are located
pathname = "E:/Dr. Brattin Project/Part 1/completed txt docs" ##sub out the e depending on computer being used.
##make sure to install these packages first!
library(lsa)
library(tm)
options(scipen = 999)
##read files into a document-term matrix
myMatrix = textmatrix(pathname,
minWordLength = 1,
stopwords = stopwords_en,
stemming = TRUE)
##setup
##set path to where txt files are located
pathname = "E:/Dr. Brattin Project/Part 1/completed txt docs" ##sub out the e depending on computer being used.
##make sure to install these packages first!
library(lsa)
library(tm)
options(scipen = 999)
##read files into a document-term matrix
myMatrix = textmatrix(pathname,
minWordLength = 1,
stopwords = stopwords_en,
stemming = TRUE)
##setup
##set path to where txt files are located
pathname = "E:/Dr. Brattin Project/Part 1/completed txt docs" ##sub out the e depending on computer being used.
##make sure to install these packages first!
library(lsa)
library(tm)
options(scipen = 999)
##read files into a document-term matrix
myMatrix = textmatrix(pathname,
minWordLength = 1,
stopwords = stopwords_en,
stemming = TRUE)
setwd("F:/02 Missouri State/Dr. Brattin Project/Part 1")
##read files into a document-term matrix
myMatrix = textmatrix(pathname,
minWordLength = 1,
stopwords = stopwords_en,
stemming = TRUE)
setwd("~/LSA")
##setup
##set path to where txt files are located
pathname = "C:/Users/nickm.000/Documents/LSA/completed txt docs" ##sub out the e depending on computer being used.
##make sure to install these packages first!
library(lsa)
library(tm)
options(scipen = 999)
##read files into a document-term matrix
myMatrix = textmatrix(pathname,
minWordLength = 1,
stopwords = stopwords_en,
stemming = TRUE)
myMatrix = lw_logtf(myMatrix) * gw_idf(myMatrix)
myMatrix
##create the lsa space
myLSAspace = lsa(myMatrix, dims=dimcalc_share())
# display it as a textmatrix again for viewing
round(as.textmatrix(myLSAspace),2)
# display it as a textmatrix again
myNewMatrix = as.textmatrix(myLSAspace)
myNewMatrix
summary(myNewMatrix)
matrixtable = table(myNewMatrix)
matrixtable
##compare cosines of terms
x = cosine(myNewMatrix) ##semantic similarity overlap
View(x)
y = cor(myNewMatrix)  ##pearson correlations
View(y)
View(myLSAspace)
View(myLSAspace)
myLSAspace[["sk"]]
setwd("~/GitHub/Trevor-Honors-Thesis/1 Output/Ex 1/Raw")
####Ex 1 Analyses####
size = read.csv("Ex 1 Scored Output/Size.csv")
highlight = read.csv("Ex 1 Scored Output/Highlight.csv")
control = read.csv("JOL3.csv")
library(ez)
library(data.table)
library(reshape)
library(Hmisc)
##Get sample size
length(unique(size$Username))
length(unique(highlight$Username))
length(unique(control$Username))
colnames(size)[7] = "Direction"
colnames(highlight)[7] = "Direction"
colnames(control)[7] = "Direction"
##Remove punctuation/special characters from JOLs
size$Response.JOL =  gsub("[[:punct:]]", "", size$Response.JOL)
size$Response.JOL =  gsub("I", NA, size$Response.JOL)
#Make Size jols numeric
size$Response.JOL = as.numeric(size$Response.JOL)
##Get descriptives
summary(size)
summary(highlight)
summary(control)
#Remove out of range JOLs
size$Response.JOL[size$Response.JOL > 100] = NA
highlight$Response.JOL[highlight$Response.JOL > 100] = NA
control$Response.JOL[control$Response.JOL > 100] = NA
##Get means
##JOLs
tapply(size$Response.JOL, size$Direction, mean, na.rm = T)
tapply(highlight$Response.JOL, highlight$Direction, mean, na.rm = T)
tapply(control$Response.JOL, control$Direction, mean, na.rm = T)
##Recall
tapply(size$Recall_Score, size$Direction, mean, na.rm = T)
tapply(highlight$Recall_Score, highlight$Direction, mean, na.rm = T)
tapply(control$Recall_Score, control$Direction, mean, na.rm = T)
##Now look at each manipulation
##Size
tapply(size$Response.JOL, list(size$Procedure.Trial.Type, size$Direction), mean, na.rm = T)
tapply(size$Recall_Score, list(size$Procedure.Trial.Type, size$Direction), mean, na.rm = T)
##Highlight
tapply(highlight$Response.JOL, list(highlight$Procedure.Trial.Type, highlight$Direction), mean, na.rm = T)
tapply(highlight$Recall_Score, list(highlight$Procedure.Trial.Type, highlight$Direction), mean, na.rm = T)
##Control
tapply(control$Response.JOL, control$Direction, mean, na.rm = T)
tapply(control$Recall_Score, control$Direction, mean, na.rm = T)
####Write output to .csv####
##Need subject level means
##Start with Control
control2 = control[ , -c(2:6, 8, 10:12)]
control_jol = control2[ , -4]
control_recall = control2[ , -3]
##Get subject level means by direction
control_jol2 = cast(control_jol, Username ~ Direction, mean, na.rm = T)
control_recall2 = cast(control_recall, Username ~ Direction, mean, na.rm = T)
####Now do it again for size####
size2 = size[ , -c(2:6, 9, 11:13)]
size.small = subset(size2,
size2$Procedure.Trial.Type == "JOL_Small")
size.large = subset(size2,
size2$Procedure.Trial.Type == "JOL_Large")
size.small.jol = size.small[ , -c(3,5)]
size.small.recall = size.small[ , -c(3:4)]
size.large.jol = size.large[ , -c(3,5)]
size.large.recall = size.large[ , -c(3:4)]
size.small.jol2 = cast(size.small.jol, Username ~ Direction, mean, na.rm = T)
size.small.recall2 = cast(size.small.recall, Username ~ Direction, mean, na.rm = T)
size.large.jol2 = cast(size.large.jol, Username ~ Direction, mean, na.rm = T)
size.large.recall2 = cast(size.large.recall, Username ~ Direction, mean, na.rm = T)
####Now for highlights####
highlight2 = highlight[ , -c(2:6, 9, 11:13)]
highlight.yes = subset(highlight2,
highlight2$Procedure.Trial.Type == "JOL_H")
highlight.no = subset(highlight2,
highlight2$Procedure.Trial.Type == "JOL")
highlight.yes.jol = highlight.yes[ , -c(3,5)]
highlight.yes.recall = highlight.yes[ , -c(3:4)]
highlight.no.jol = highlight.no[ , -c(3,5)]
highlight.no.recall = highlight.no[ , -c(3:4)]
highlight.yes.jol2 = cast(highlight.yes.jol, Username ~ Direction, mean, na.rm = T)
highlight.yes.recall2 = cast(highlight.yes.recall, Username ~ Direction, mean, na.rm = T)
highlight.no.jol2 = cast(highlight.no.jol, Username ~ Direction, mean, na.rm = T)
highlight.no.recall2 = cast(highlight.no.recall, Username ~ Direction, mean, na.rm = T)
control = na.omit(control)
size.large = na.omit(size.large)
size.small = na.omit(size.small)
highlight.yes = na.omit(highlight.yes)
highlight.no = na.omit(highlight.no)
####Control Gammas####
Control_F = subset(control, control$Direction == "F")
Control_B = subset(control, control$Direction == "B")
control_S = subset(control, control$Direction == "S")
control_U = subset(control, control$Direction == "U")
#Use loops to get each participant's mean gamma between JOLs and Recall
#Forward
empty = data.frame()
for (i in unique(Control_F$Username)){
temp = subset(Control_F, Control_F$Username == i)
g = rcorr.cens(temp$Response.JOL, temp$Recall_Score, outx = TRUE)[2]
g = unname(g)
temp2 = data.frame(i, g)
empty = rbind(temp2, empty)
}
Gammas_Control_F = empty
#Backward
empty = data.frame()
for (i in unique(Control_B$Username)){
temp = subset(Control_B, Control_B$Username == i)
g = rcorr.cens(temp$Response.JOL, temp$Recall_Score, outx = TRUE)[2]
g = unname(g)
temp2 = data.frame(i, g)
empty = rbind(temp2, empty)
}
Gammas_Control_B = empty
#Symmetrical
empty = data.frame()
for (i in unique(control_S$Username)){
temp = subset(control_S, control_S$Username == i)
g = rcorr.cens(temp$Response.JOL, temp$Recall_Score, outx = TRUE)[2]
g = unname(g)
temp2 = data.frame(i, g)
empty = rbind(temp2, empty)
}
Gammas_Control_S = empty
#Unrelated
empty = data.frame()
for (i in unique(control_U$Username)){
temp = subset(control_U, control_U$Username == i)
g = rcorr.cens(temp$Response.JOL, temp$Recall_Score, outx = TRUE)[2]
g = unname(g)
temp2 = data.frame(i, g)
empty = rbind(temp2, empty)
}
25/39
34/39
39-12
27/39
25/41
28/41
41-19
22/41
26/41
32/41
41-19
22-41
22/41
28/32
21/32
22/32
25/36
25/36
32-21
11/32
26/37
21/3
21/37
37-18
19/37
29/41
28/41
10/41
31/41
32/39
28/39
29/39
devtools::install_github("npm27/lrd")
install.packages("stringi")
devtools::install_github("npm27/lrd")
install.packages("glue")
install.packages("glue")
devtools::install_github("npm27/lrd")
.libPaths()
